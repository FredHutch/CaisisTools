{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CaisisImport. A utility to prepare a Caisis-to-Excel export for import into Oncoscape (via cBioPortal format).\n",
    "\n",
    "# Steps:\n",
    "# . Limit by disease\n",
    "# . ExportAsTSVs\n",
    "# . ZeroDates\n",
    "# . \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import errno\n",
    "import sys\n",
    "#import datetime\n",
    "from typing import List\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "dataset_folder = '../Caisis_NonPublicData/Brain_nov2021'\n",
    "diseaseChosen = 'Brain'\n",
    "## knownTables = ['Demographics', 'Encounters', 'ClinicalStage', 'LabTests', 'PathTest', 'SocialHistory', 'LabTestGenetics', 'PathStageGrade', 'RadiationTherapy',  ]\n",
    "# table Status is treated separately, first.\n",
    "knownTables = ['Clinical Stages', 'Demographics', 'Encounters', 'Medical Therapy', 'Pathology', 'Procedures', 'Radiation', 'Social History']\n",
    "date_format = '%Y-%M-%d'  # '%d-%b-%y'   #'%b %d %Y %I:%M%p'\n",
    "#days_before_dx_to_include = 0  # if 30, can include events up to 30 days before the diagnosis date.\n",
    "\n",
    "## -- internal --\n",
    "patients_first_dx = pd.DataFrame()   # just PatientId and DiagnosisDate\n",
    "data_clinical_patient = pd.DataFrame() # Will become the data_clinical_patient table.\n",
    "loaded_tables_dict = {}\n",
    "data_clinical_patient = None\n",
    "datafiles_fields = {\n",
    "    'patient': []   #not including PATIENT_ID\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImportField:\n",
    "    source_name:str\n",
    "    final_name:str\n",
    "    type:str = 'STRING'  # STRING, NUMBER, or DATE (DATE gets turned into STING in final TSV files.)\n",
    "    conversion_function = None\n",
    "\n",
    "    def __init__(self, source_name, final_name, type=\"STRING\", conversion_function=None ):\n",
    "        self.source_name = source_name\n",
    "        self.final_name = final_name\n",
    "        self.type = type\n",
    "        self.conversion_function = conversion_function\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.source_name +\"->\"+ self.final_name+\", type=\"+self.type+\".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file_and_folder(filename, obj):\n",
    "    if not os.path.exists(os.path.dirname(filename)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(filename))\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(obj)\n",
    "\n",
    "def patients_and_descriptive_header(df:pd.DataFrame, header):\n",
    "    # TBD: note header in separate place\n",
    "    str_ids = df.to_string(index=False)\n",
    "    a =  str_ids  # header + \"\\n\" + str_ids\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_patients_first_dx():\n",
    "    global patients_first_dx, data_clinical_patient, dataset_folder\n",
    "    print(\"\\nSTEP 1: Find patients' first diagnosis date.\")\n",
    "    print(dataset_folder)\n",
    "    status_fullpath = dataset_folder +'/raw_csv/Status.csv'\n",
    "    if not os.path.exists(dataset_folder +'/raw_csv'):\n",
    "        sys.exit('ERROR: Cannot find folder \"raw_csv\".')\n",
    "\n",
    "    if not os.path.exists(status_fullpath):\n",
    "        sys.exit('ERROR: Status.csv file not found at ' + status_fullpath)\n",
    "\n",
    "    tbl_status = pd.read_csv(status_fullpath) #'Demographics.csv')\n",
    "    tbl_status['Date'] =pd.to_datetime(tbl_status.StatusDate)\n",
    "    tbl_status['PatientId'] =  tbl_status['PatientId'].astype(str)\n",
    "\n",
    "    dxRows = tbl_status[tbl_status.Status.eq('Diagnosis Date')]\n",
    "    diseaseRows = dxRows[dxRows.StatusDisease.eq(diseaseChosen)].sort_values('Date')\n",
    "\n",
    "    dxNanRows = diseaseRows[diseaseRows.Date.isna()][['PatientId']]\n",
    "    if(dxNanRows.size > 0):\n",
    "        print('CHECK NoDxDate? REPORT NoDxDate.txt has *' +str(dxNanRows.size)+'* diagnoses of '+diseaseChosen+' without diagnosis dates.')\n",
    "        report_body = patients_and_descriptive_header(dxNanRows, 'Patients with \"'+diseaseChosen+\" but no DiagnosisDate:\")\n",
    "    #    save_file_and_folder('reports/NoDxDate.txt', report_body)\n",
    "        save_file_and_folder(dataset_folder+'/reports/NoDxDate.txt', report_body)\n",
    "    else:\n",
    "        print('CHECK NoDxDate? OK')\n",
    "        print('TBD: delete existing NoDxDate.txt report.')\n",
    "        if os.path.exists(dataset_folder+'/reports/NoDxDate.txt'):\n",
    "            os.remove(dataset_folder+'/reports/NoDxDate.txt')\n",
    "            print('REMOVED NoDxDate.txt')\n",
    "            \n",
    "    diseaseDatedRows = diseaseRows[diseaseRows.Date.isna()==False]\n",
    "    patientid_date_dict = {}\n",
    "    for index, row in diseaseDatedRows.iterrows():\n",
    "        pid = str(row['PatientId'])\n",
    "        if((pid in patientid_date_dict) == False):\n",
    "            patientid_date_dict[pid] = row['Date']\n",
    "        else:\n",
    "            pass\n",
    "    print('Resulting patient IDs = ' + str(len(patientid_date_dict)))   \n",
    "\n",
    "    data = []\n",
    "    for key in patientid_date_dict.keys():\n",
    "        new_row = [key, patientid_date_dict[key]]\n",
    "        data.append(new_row)\n",
    "    patients_first_dx = pd.DataFrame(data, columns=[\"PatientId\", \"DiagnosisDate\"])\n",
    "    data_clinical_patient = patients_first_dx.copy()\n",
    "\n",
    "    report_body = patients_and_descriptive_header(patients_first_dx, 'Patients First Diagnosis Date')\n",
    "    \n",
    "    save_file_and_folder(dataset_folder+'/reports/PatientsFirstDx.txt', report_body)\n",
    "    #patients_first_dx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_tables():\n",
    "    global loaded_tables_dict\n",
    "    print(\"\\nSTEP 2: Load all CSV tables.\")\n",
    "    for tableName in knownTables:\n",
    "        full_path = dataset_folder+'/raw_csv/'+tableName+'.csv'\n",
    "        if not os.path.exists(full_path):\n",
    "            print(\"WARN -- missing table \"+tableName)\n",
    "        else:\n",
    "            print('Reading ' + tableName+'.csv...')\n",
    "            df = pd.read_csv(full_path)\n",
    "            df = df.astype({\"PatientId\": str})\n",
    "            #df.set_index('PatientId', inplace=True)\n",
    "            #print(df.head(2))\n",
    "            loaded_tables_dict[tableName] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_lookup_field = 'notPtGender'  # placeholder.\n",
    "noval_list = []   # List of patient IDs with no associated value in one or more of the import_fields. Use this for reporting. \n",
    "\n",
    "\n",
    "# imports: a dictionary of column name from the tname table, where value is a function to convert data\n",
    "def import_to_patient_table(tname, import_fields:List[ImportField]):\n",
    "    global patients_first_dx, data_clinical_patient, loaded_tables_dict, current_lookup_field, noval_list\n",
    "    if (tname in loaded_tables_dict) == False:\n",
    "        print(\"WARN -- Could not process table \"+tname)\n",
    "    else:\n",
    "        current_table = loaded_tables_dict[tname]\n",
    "        for ifield in import_fields:\n",
    "\n",
    "            if ifield.source_name in current_table.columns:\n",
    "                data_clinical_patient.insert(1, ifield.final_name, None)\n",
    "               # global current_lookup_field\n",
    "                current_lookup_field= ifield.source_name\n",
    "                print(\"Looking for field \" + tname+\".\"+current_lookup_field)\n",
    "                noval_list.clear()\n",
    "\n",
    "                def get_field_value(pid):\n",
    "                    global current_lookup_field, noval_list\n",
    "                    gg = current_table.loc[current_table['PatientId'] == str(pid)]\n",
    "                    hh = gg[current_lookup_field]\n",
    "                    val = None\n",
    "                    try:\n",
    "                        val = hh.iloc[0] \n",
    "                        if ifield.type=='NUMBER':\n",
    "                            val = val # convert to number\n",
    "                        if ifield.type=='DATE':\n",
    "                            print(\"val...\"+str(val))\n",
    "                            if isinstance(val, str):\n",
    "                                val = datetime.strptime(val, date_format)\n",
    "                            else:\n",
    "                                val=\"NOTSTR\" # TBD: error reporting\n",
    "                        try:\n",
    "                            return val\n",
    "                        except:\n",
    "                            noval_list.append(pid)\n",
    "                            return None\n",
    "                    except:\n",
    "                        print(\"ERROR \"+current_lookup_field+\", \"+str(pid)+\"   \"+str(val)+\".\")\n",
    "                        typef, value, traceback = sys.exc_info()\n",
    "                        print('Error value '+ str (value))\n",
    "\n",
    "\n",
    "                new_values = data_clinical_patient['PatientId'].apply(get_field_value)\n",
    "                if len(noval_list) > 0 :\n",
    "                    percent_str = \"{0:.0%}\".format(len(noval_list) / new_values.shape[0])\n",
    "                    print(\"- Field \" + tname+\".\"+current_lookup_field + \" had \" + str(len(noval_list)) + \" missing entries. (\"+percent_str+\" empty)\")\n",
    "                    #print(str( len(noval_list) / new_values.shape[0]))\n",
    "\n",
    "\n",
    "                data_clinical_patient[ifield.final_name] = new_values\n",
    "                #print(data_clinical_patient.head(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1933-07-02'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = datetime.strptime('1933-07-02', '%Y-%M-%d')   # '%d-%b-%y'   #'%b %d %Y %I:%M%p'\n",
    "datetime.strftime(val, '%Y-%M-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_fields_to_patient_table():\n",
    "    # This is the core of specifying which fields we want to import. May change between datasets, so consider moving to an external file.\n",
    "    \n",
    "    print(\"\\nSTEP 3: Import columns to patient table.\")\n",
    "    import_fields = [\n",
    "        ImportField('PtGender', final_name='Sex') ,   #, conversion_function=None),\n",
    "        ImportField('PtBirthDate', final_name='BirthDate', type=\"DATE\" )\n",
    "    ]\n",
    "    import_to_patient_table('Demographics', import_fields)\n",
    "    datafiles_fields['patient'].extend(import_fields)\n",
    "\n",
    "    import_fields = [\n",
    "        ImportField('SocHxTobaccoType', final_name='Tobacco_Use'),\n",
    "        ImportField('SocHxTobaccoYears', final_name='Tobacco_Years' ), #SocHxAlcohol\n",
    "        ImportField('SocHxAlcohol', final_name='Alcohol_Use')\n",
    "    ]\n",
    "    import_to_patient_table('Social History', import_fields)\n",
    "    datafiles_fields['patient'].extend(import_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_types(filename):\n",
    "    rr=reversed(list(map(lambda s: s.type, datafiles_fields[filename])))\n",
    "    q=[]\n",
    "    if filename=='patient':\n",
    "        q.append('STRING') # for 'PatientID'\n",
    "    q.extend(list(rr))\n",
    "    if filename=='patient':\n",
    "        q.append('DATE') # for 'DiagnosisDate'\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file_as_cbioportal(df:pd.DataFrame, filename):\n",
    "    output_filename = 'data_clinical_'+filename+'.txt'\n",
    "    full_filename = dataset_folder + \"/01_with_headers/\" + output_filename\n",
    "    if not os.path.exists(os.path.dirname(full_filename)):\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(full_filename))\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "\n",
    "    with open(full_filename, \"w\") as f:\n",
    "        col_names_raw = list(data_clinical_patient.columns.values)\n",
    "        col_names = [x.upper() for x in col_names_raw]\n",
    "        col_types = get_col_types(filename)  #  ['STRING' ]* len(col_names)\n",
    "        # f.write('>>>'+str(\" \".join(str(datafiles_fields[filename]))))\n",
    "\n",
    "        f.write('#' + '\\t'.join(col_names) + \"\\n\") # header 1, internal name\n",
    "        f.write('#' + '\\t'.join(col_names) + \"\\n\")  # header 2, description\n",
    "        f.write('#' + '\\t'.join(col_types) + \"\\n\")  # header 3, type (STRING or NUMBER)  <<<<<\n",
    "        f.write('#' + '\\t'.join(['1'] * len(col_names)) + \"\\n\")  # header 4, position\n",
    "        f.write('\\t'.join(col_names) + \"\\n\")  # header 5, readable name\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            output_row = []\n",
    "            row_as_list = list(row)\n",
    "            i = 0\n",
    "            for item in row_as_list:\n",
    "                cleaned_item = str(item)\n",
    "                if item == None:\n",
    "                    cleaned_item = \"NA\"\n",
    "                else:\n",
    "                    if 'time' in str(type(item)):   # datetime.datetime or pandas...timestamp.Timestamp\n",
    "                        cleaned_item = datetime.strftime(item, '%Y-%M-%d')\n",
    "                output_row.append(cleaned_item)\n",
    "                i = i+1\n",
    "            items_to_str = '\\t'.join(output_row)\n",
    "            f.write(items_to_str + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_files_as_cbioportal():\n",
    "    # clear out the folder, if it has files\n",
    "    dir = dataset_folder + \"/01_with_headers/\" \n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "        print(\"Created Directory : \", dir)\n",
    "    else:\n",
    "        print(\"Directory already existed : \", dir)  \n",
    "        import shutil\n",
    "        for root, dirs, files in os.walk(dir):\n",
    "            for f in files:\n",
    "                os.unlink(os.path.join(root, f))\n",
    "\n",
    "\n",
    "    # loop through all table files\n",
    "    filename = 'patient'\n",
    "    write_file_as_cbioportal(data_clinical_patient, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_patients_first_dx()\n",
    "print(patients_first_dx.shape)\n",
    "load_all_tables()\n",
    "import_fields_to_patient_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already existed :  ../Caisis_NonPublicData/Brain_nov2021/01_with_headers/\n"
     ]
    }
   ],
   "source": [
    "write_files_as_cbioportal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data_clinical_patient.columns.values))\n",
    "print(data_clinical_patient['BirthDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zero_dates import square_plus, zero_dates\n",
    "\n",
    "square_plus(3)\n",
    "\n",
    "zero_dates('../Caisis_NonPublicData/Prostate_TAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_clinical_patient = patients_first_dx.copy()\n",
    "import_fields_to_patient_table()\n",
    "print(data_clinical_patient)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
